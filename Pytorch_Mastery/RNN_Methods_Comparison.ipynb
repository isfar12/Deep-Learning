{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459c0fb7",
   "metadata": {},
   "source": [
    "# RNN Implementation Methods\n",
    "\n",
    "Different ways to implement RNNs in PyTorch with code examples.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "1. [Method 1: Manual RNN](#manual)\n",
    "2. [Method 2: Built-in nn.RNN](#builtin)\n",
    "3. [Method 3: LSTM & GRU](#lstm)\n",
    "4. [Method 4: Bidirectional RNN](#bidirectional)\n",
    "5. [Quick Comparison](#comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8bb35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 10, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Sample data for all examples\n",
    "batch_size = 32\n",
    "seq_len = 10\n",
    "input_size = 50\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "\n",
    "# Create sample batch\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "print(f\"Input shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb93a55",
   "metadata": {},
   "source": [
    "<a id='manual'></a>\n",
    "# Method 1: Manual RNN\n",
    "\n",
    "Build RNN from scratch by processing one time step at a time.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Manually loop through each time step\n",
    "- Full control over the process\n",
    "- Slower due to Python loops\n",
    "- Good for learning RNN internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135d8436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10])\n",
      "Hidden shape: torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "class ManualRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.tanh(self.i2h(combined))\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "model = ManualRNN(input_size, hidden_size, output_size)\n",
    "hidden = model.init_hidden(batch_size)\n",
    "\n",
    "for t in range(seq_len):\n",
    "    output, hidden = model(x[:, t, :], hidden)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Hidden shape: {hidden.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1293a5d7",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**\n",
    "\n",
    "1. **Two Linear Layers:**\n",
    "   - `i2h`: Transforms concatenated input to hidden state\n",
    "   - `i2o`: Transforms concatenated input to output\n",
    "\n",
    "2. **Forward Process:**\n",
    "   - Concatenate current input with previous hidden state\n",
    "   - Update hidden state using tanh activation\n",
    "   - Compute output from the combined vector\n",
    "\n",
    "3. **Manual Loop Required:**\n",
    "   - Must call `forward()` once per time step\n",
    "   - Hidden state carries information across time steps\n",
    "   - Final output after processing all time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e483183",
   "metadata": {},
   "source": [
    "<a id='builtin'></a>\n",
    "# Method 2: Built-in nn.RNN\n",
    "\n",
    "Use PyTorch's optimized RNN layer.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Process entire sequence in one call\n",
    "- 10-50x faster than manual RNN\n",
    "- Optimized C++/CUDA implementation\n",
    "- No manual time step looping needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7997c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class BuiltInRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "        output = self.fc(rnn_out[:, -1, :])\n",
    "        return output\n",
    "\n",
    "model = BuiltInRNN(input_size, hidden_size, output_size)\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ba593",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**\n",
    "\n",
    "1. **Single RNN Layer:**\n",
    "   - `nn.RNN()`: PyTorch's optimized RNN implementation\n",
    "   - `batch_first=True`: Input shape is (batch, seq, features)\n",
    "\n",
    "2. **Forward Process:**\n",
    "   - `rnn_out`: Contains output for ALL time steps (batch, seq, hidden)\n",
    "   - We extract `[:, -1, :]` to get only the last time step\n",
    "   - Pass through linear layer for final prediction\n",
    "\n",
    "3. **No Manual Loop:**\n",
    "   - Entire sequence processed in one call\n",
    "   - Much faster than manual looping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd529df",
   "metadata": {},
   "source": [
    "<a id='lstm'></a>\n",
    "# Method 3: LSTM & GRU\n",
    "\n",
    "Advanced RNN variants that handle long-term dependencies better.\n",
    "\n",
    "**LSTM (Long Short-Term Memory):**\n",
    "- Solves vanishing gradient problem\n",
    "- Has cell state + hidden state\n",
    "- Best for long sequences (100+ time steps)\n",
    "- More parameters than vanilla RNN\n",
    "\n",
    "**GRU (Gated Recurrent Unit):**\n",
    "- Simpler than LSTM (no cell state)\n",
    "- Faster training than LSTM\n",
    "- Similar performance to LSTM\n",
    "- Fewer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f66e47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM output: torch.Size([32, 10])\n",
      "GRU output: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        return output\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        gru_out, hidden = self.gru(x)\n",
    "        output = self.fc(gru_out[:, -1, :])\n",
    "        return output\n",
    "\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size)\n",
    "gru_model = GRUModel(input_size, hidden_size, output_size)\n",
    "\n",
    "lstm_output = lstm_model(x)\n",
    "gru_output = gru_model(x)\n",
    "\n",
    "print(f\"LSTM output: {lstm_output.shape}\")\n",
    "print(f\"GRU output: {gru_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004009b",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**\n",
    "\n",
    "1. **LSTM Returns Two States:**\n",
    "   - `hidden`: Short-term memory\n",
    "   - `cell`: Long-term memory (unique to LSTM)\n",
    "   - Unpack both from LSTM output: `(hidden, cell)`\n",
    "\n",
    "2. **GRU Returns One State:**\n",
    "   - Only `hidden` state (no cell state)\n",
    "   - Simpler architecture than LSTM\n",
    "\n",
    "3. **Both Models:**\n",
    "   - Use `[:, -1, :]` to get last time step\n",
    "   - Apply linear layer for classification\n",
    "   - LSTM has ~3x more parameters than GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21d916",
   "metadata": {},
   "source": [
    "<a id='bidirectional'></a>\n",
    "# Method 4: Bidirectional RNN\n",
    "\n",
    "Process sequences in both forward and backward directions.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Reads sequence left-to-right AND right-to-left\n",
    "- Combines information from both directions\n",
    "- 2x slower than unidirectional\n",
    "- Better accuracy when full sequence is available\n",
    "- Cannot use for real-time/streaming tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdf236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, \n",
    "                          batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "        output = self.fc(rnn_out[:, -1, :])\n",
    "        return output\n",
    "\n",
    "model = BiRNN(input_size, hidden_size, output_size)\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda00c6",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**\n",
    "\n",
    "1. **Bidirectional Flag:**\n",
    "   - `bidirectional=True`: Processes sequence both ways\n",
    "   - Forward RNN: Left → Right\n",
    "   - Backward RNN: Right → Left\n",
    "\n",
    "2. **Output Size Doubles:**\n",
    "   - `hidden_size * 2` in the linear layer\n",
    "   - Concatenates forward and backward hidden states\n",
    "   - Example: hidden_size=128 → BiRNN outputs 256 features\n",
    "\n",
    "3. **Usage:**\n",
    "   - Same input/output interface as regular RNN\n",
    "   - Automatically handles both directions internally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b7d38",
   "metadata": {},
   "source": [
    "<a id='stacked'></a>\n",
    "# Method 5: Stacked/Deep RNN\n",
    "\n",
    "Stack multiple RNN layers for deeper learning.\n",
    "\n",
    "**Key characteristics:**\n",
    "- Multiple RNN layers stacked vertically\n",
    "- Each layer learns different levels of abstraction\n",
    "- Better for complex patterns\n",
    "- More parameters = more training time\n",
    "- Typically use 2-4 layers (diminishing returns after that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75418fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "class StackedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "        output = self.fc(rnn_out[:, -1, :])\n",
    "        return output\n",
    "\n",
    "model = StackedRNN(input_size, hidden_size, output_size, num_layers=3)\n",
    "output = model(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4e2ad",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**\n",
    "\n",
    "1. **Number of Layers:**\n",
    "   - `num_layers=3`: Creates 3 RNN layers stacked vertically\n",
    "   - Layer 1 output → Layer 2 input → Layer 3 input\n",
    "   - Each layer learns different level of abstraction\n",
    "\n",
    "2. **Same Interface:**\n",
    "   - Only difference from single layer: `num_layers` parameter\n",
    "   - Input/output shapes remain the same\n",
    "   - Hidden state has shape (num_layers, batch, hidden_size)\n",
    "\n",
    "3. **Trade-off:**\n",
    "   - More layers = better learning capacity\n",
    "   - More layers = more training time\n",
    "   - Typically use 2-4 layers in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f34d81",
   "metadata": {},
   "source": [
    "<a id='seq2seq'></a>\n",
    "# Method 6: Seq2Seq (Encoder-Decoder)\n",
    "\n",
    "For tasks where input and output have different lengths.\n",
    "\n",
    "**Architecture:**\n",
    "- **Encoder**: Compresses input sequence into context vector\n",
    "- **Decoder**: Generates output sequence from context vector\n",
    "\n",
    "**Use cases:**\n",
    "- Machine translation (English → French)\n",
    "- Text summarization (long text → short summary)\n",
    "- Chatbots (question → answer)\n",
    "\n",
    "**Key point:** Input length ≠ Output length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        rnn_out, hidden = self.rnn(x, hidden)\n",
    "        output = self.fc(rnn_out)\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size)\n",
    "        self.decoder = Decoder(output_size, hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        context = self.encoder(src)\n",
    "        output, _ = self.decoder(tgt, context)\n",
    "        return output\n",
    "\n",
    "model = Seq2Seq(input_size, hidden_size, output_size)\n",
    "src = torch.randn(batch_size, seq_len, input_size)\n",
    "tgt = torch.randn(batch_size, seq_len, output_size)\n",
    "output = model(src, tgt)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11644383",
   "metadata": {},
   "source": [
    "**Code Walkthrough:**\n",
    "\n",
    "1. **Encoder:**\n",
    "   - Takes input sequence of any length\n",
    "   - Returns only the final hidden state (context vector)\n",
    "   - This context vector \"summarizes\" the entire input\n",
    "\n",
    "2. **Decoder:**\n",
    "   - Starts with encoder's context as initial hidden state\n",
    "   - Takes target sequence as input\n",
    "   - Generates output sequence step by step\n",
    "\n",
    "3. **Seq2Seq Model:**\n",
    "   - Combines encoder + decoder\n",
    "   - `src`: Source sequence (e.g., English sentence)\n",
    "   - `tgt`: Target sequence (e.g., French sentence)\n",
    "   - Input and output can have different lengths!\n",
    "\n",
    "4. **Flow:**\n",
    "   ```\n",
    "   src → Encoder → context → Decoder → output\n",
    "         (compress)           (generate)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f0d53",
   "metadata": {},
   "source": [
    "<a id='comparison'></a>\n",
    "# Quick Comparison\n",
    "\n",
    "## Architecture Comparison\n",
    "\n",
    "| Method | Use Case | Pros | Cons |\n",
    "|--------|----------|------|------|\n",
    "| **Manual RNN** | Learning | Full control | Slow, complex |\n",
    "| **nn.RNN** | Simple tasks | Fast, easy | Vanishing gradients |\n",
    "| **LSTM** | Long sequences | Good memory | More parameters |\n",
    "| **GRU** | Balance | Faster than LSTM | Less capacity |\n",
    "| **Bidirectional** | Context matters | Both directions | 2x slower |\n",
    "| **Seq2Seq** | Translation | Variable I/O | Complex training |\n",
    "\n",
    "## When to Use What?\n",
    "\n",
    "**RNN**: Short sequences, simple patterns\n",
    "- Sentiment analysis (short reviews)\n",
    "- Simple time series\n",
    "\n",
    "**LSTM**: Long sequences, long-term dependencies\n",
    "- Language modeling\n",
    "- Speech recognition\n",
    "- Long text classification\n",
    "\n",
    "**GRU**: Similar to LSTM but faster\n",
    "- When LSTM works but speed matters\n",
    "- Less data available\n",
    "\n",
    "**Bidirectional**: Context from both sides needed\n",
    "- Named Entity Recognition\n",
    "- Fill-in-the-blank tasks\n",
    "- Not for real-time/streaming\n",
    "\n",
    "**Seq2Seq**: Variable length input/output\n",
    "- Machine translation\n",
    "- Text summarization\n",
    "- Chatbots\n",
    "\n",
    "## Parameter Count Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458801c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual RNN      24,702 parameters\n",
      "nn.RNN          24,330 parameters\n",
      "LSTM            93,450 parameters\n",
      "GRU             70,410 parameters\n",
      "BiRNN           48,650 parameters\n"
     ]
    }
   ],
   "source": [
    "# Compare parameter counts\n",
    "models = {\n",
    "    'Manual RNN': ManualRNN(input_size, hidden_size, output_size),\n",
    "    'nn.RNN': BuiltInRNN(input_size, hidden_size, output_size),\n",
    "    'LSTM': LSTMModel(input_size, hidden_size, output_size),\n",
    "    'GRU': GRUModel(input_size, hidden_size, output_size),\n",
    "    'BiRNN': BiRNN(input_size, hidden_size, output_size),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{name:15} {params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b9f0b",
   "metadata": {},
   "source": [
    "## Training Tips\n",
    "\n",
    "### 1. Gradient Clipping\n",
    "```python\n",
    "nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "```\n",
    "\n",
    "### 2. Learning Rate\n",
    "- Start with 0.001 for Adam\n",
    "- Use learning rate scheduling\n",
    "\n",
    "### 3. Hidden Size\n",
    "- Start with 128 or 256\n",
    "- Increase if underfitting\n",
    "- Decrease if overfitting\n",
    "\n",
    "### 4. Num Layers\n",
    "- 1-2 layers usually sufficient\n",
    "- 3-4 for complex tasks\n",
    "- More layers = harder to train\n",
    "\n",
    "### 5. Dropout\n",
    "```python\n",
    "nn.RNN(input_size, hidden_size, num_layers, dropout=0.5)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
