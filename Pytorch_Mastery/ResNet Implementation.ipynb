{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80ac13c",
   "metadata": {},
   "source": [
    "# ResNet Implementation: Deep Networks That Actually Work!\n",
    "\n",
    "## The Problem: Very Deep Networks Fail\n",
    "\n",
    "When we train very deep neural networks, they often struggle to learn. Adding more layers doesn't always make the model smarter — it can actually make it worse, because information gets \"washed out\" or distorted as it travels through so many layers.\n",
    "\n",
    "---\n",
    "\n",
    "## 🍕 Silly Example: The Pizza Recipe Telephone Game\n",
    "\n",
    "**Imagine teaching someone to make pizza through a chain of 50 people:**\n",
    "\n",
    "### Traditional Deep Network (No Skip Connections):\n",
    "```\n",
    "You → Person 1 → Person 2 → ... → Person 50 → Final Pizza\n",
    "```\n",
    "\n",
    "**Instructions start:** \"Mix 2 cups flour, 1 cup water, add yeast...\"\n",
    "\n",
    "**After 50 people:** \"Mix 7 spoons of... something? Add water? Or was it milk? 🤷\"\n",
    "\n",
    "**Result:** 🍕❌ Terrible pizza! Information got corrupted through the chain.\n",
    "\n",
    "---\n",
    "\n",
    "### ResNet (With Skip Connections):\n",
    "```\n",
    "You → Person 1 → Person 2 → ... → Person 50 → Final Pizza\n",
    " └────────────────────────────────────────────┘ (You also tell them directly!)\n",
    "```\n",
    "\n",
    "**What happens:**\n",
    "- Each person makes small improvements: \"Add more salt\", \"Knead 2 more minutes\"\n",
    "- But you ALSO give them the original recipe directly (skip connection!)\n",
    "- Final person gets: Original recipe + All improvements\n",
    "\n",
    "**Result:** 🍕✅ Amazing pizza! Original information preserved + refinements added!\n",
    "\n",
    "---\n",
    "\n",
    "## 🎓 Real Lesson\n",
    "\n",
    "**Traditional Network:** `Output = Learn_Everything(Input)`  \n",
    "**Problem:** Learning everything from scratch through 50 layers is hard!\n",
    "\n",
    "**ResNet:** `Output = Input + Learn_Only_Changes(Input)`  \n",
    "**Solution:** Just learn what needs to change! Much easier! 🚀\n",
    "\n",
    "Let's see how this works..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0797bb",
   "metadata": {},
   "source": [
    "## Visual Understanding: The Residual Learning Concept\n",
    "\n",
    "These images demonstrate the core concept behind ResNet through a super-resolution example:\n",
    "\n",
    "### Image 1: The Goal (Super Resolution)\n",
    "<figure>\n",
    "  <img src=\"asset/super_resolution.png\" alt=\"Super Resolution Process from left to right\" width=\"520\">\n",
    "</figure>\n",
    "\n",
    "**What it shows:** Low resolution image → High resolution image\n",
    "\n",
    "**The Challenge:** Training a network to directly generate the high-resolution image from scratch is difficult. The network must learn ALL the details.\n",
    "\n",
    "---\n",
    "\n",
    "### Image 2: Adding the \"Unknown\" to Create Better Output\n",
    "<figure>\n",
    "  <img src=\"asset/how_to_upsample.png\" alt=\"How to update Resolution\" width=\"520\">\n",
    "</figure>\n",
    "\n",
    "**The Formula:** `Low-Res Image + ? = High-Res Image`\n",
    "\n",
    "**Key Insight:** Instead of learning the entire high-resolution image, what if we just learn what needs to be **added** to the low-resolution image?\n",
    "\n",
    "This \"?\" is the **residual** - the missing details!\n",
    "\n",
    "---\n",
    "\n",
    "### Image 3: Computing the Residual (The Difference)\n",
    "<figure>\n",
    "  <img src=\"asset/image_minus.png\" alt=\"Image subtract from one another to get Residual\" width=\"520\">\n",
    "</figure>\n",
    "\n",
    "**The Operation:** `High-Res Image - Low-Res Image = Residual (Noise-like Pattern)`\n",
    "\n",
    "**What you see:** \n",
    "- Left: Original low-res flower\n",
    "- Middle: Target high-res flower  \n",
    "- Right: The **residual** (looks like noise/texture)\n",
    "\n",
    "**Critical Understanding:** The residual contains ONLY the fine details and corrections needed. It's much simpler to learn than the complete image!\n",
    "\n",
    "---\n",
    "\n",
    "### Image 4: Applying the Residual (Adding Back)\n",
    "<figure>\n",
    "  <img src=\"asset/residual_update.png\" alt=\"Target Residual to update\" width=\"520\">\n",
    "</figure>\n",
    "\n",
    "**The Reconstruction:** `Original + Learned Residual = Enhanced Output`\n",
    "\n",
    "**The ResNet Formula:**\n",
    "```python\n",
    "Output = Input + F(Input)\n",
    "```\n",
    "Where:\n",
    "- **Input**: Original information (passes through via skip connection)\n",
    "- **F(Input)**: Learned residual (what the conv layers learn)\n",
    "- **Output**: Enhanced result\n",
    "\n",
    "**Why This Works Better:**\n",
    "\n",
    "1. **Easier Optimization:** Learning small adjustments (residual) is easier than learning the complete transformation\n",
    "2. **Gradient Flow:** The skip connection (arrow showing addition) allows gradients to flow directly backward\n",
    "3. **Identity Preservation:** If no improvement is needed, the network can learn F(x) ≈ 0, and Output ≈ Input\n",
    "4. **Incremental Refinement:** Each layer adds small refinements rather than completely transforming the data\n",
    "\n",
    "**Real-World Analogy:**\n",
    "Think of photo editing: You don't recreate the entire photo. You apply adjustments (brightness +10, contrast +5, sharpness +3). Each adjustment is a \"residual\" that enhances the original!\n",
    "\n",
    "This is EXACTLY how ResNet works - each residual block learns small refinements to add to the input, allowing very deep networks (50-152 layers) to train successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce8afd",
   "metadata": {},
   "source": [
    "## The ResNet Formula: Learning Differences, Not Complete Transformations\n",
    "\n",
    "### 📝 Another Silly Example: The Homework Editor\n",
    "\n",
    "**Imagine you wrote an essay and need to improve it:**\n",
    "\n",
    "#### Traditional Network (Learn Everything):\n",
    "```\n",
    "Teacher: \"Write a completely new essay from scratch that's better!\"\n",
    "```\n",
    "**You:** \"But... I have to re-write EVERYTHING? Even the parts that were already good?!\" 😰  \n",
    "**Result:** Exhausting! Might make it worse! ❌\n",
    "\n",
    "---\n",
    "\n",
    "#### ResNet (Learn Only Changes):\n",
    "```\n",
    "Teacher: \"Keep your original essay. Just tell me what edits to make!\"\n",
    "```\n",
    "**You:** \"Original essay + [Fix spelling in paragraph 2, add example in paragraph 4, improve conclusion]\"  \n",
    "**Result:** Much easier! Just small improvements! ✅\n",
    "\n",
    "**The Formula:**\n",
    "```python\n",
    "Final Essay = Original Essay + Edits\n",
    "             ↑                  ↑\n",
    "         (preserved)      (learned)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### The Core Insight\n",
    "\n",
    "Instead of learning the complete transformation:\n",
    "```\n",
    "Neural Network: Input → Output (learn everything from scratch)\n",
    "```\n",
    "\n",
    "ResNet learns only the **difference** (residual):\n",
    "```\n",
    "ResNet: Input + Residual → Output (learn what needs to change)\n",
    "```\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "**Mathematical Formula:**\n",
    "```python\n",
    "Output = Input + F(Input)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **Input**: Original information (skip connection)\n",
    "- **F(Input)**: Residual learned by conv layers\n",
    "- **+**: Element-wise addition\n",
    "\n",
    "**Key Benefits:**\n",
    "\n",
    "1. **Easier Optimization:** Learning small adjustments is easier than learning complete transformations\n",
    "\n",
    "2. **Identity Mapping:** If no change is needed, network can learn F(x) ≈ 0, so Output ≈ Input\n",
    "\n",
    "3. **Gradient Flow:** Skip connection provides direct path for gradients during backpropagation\n",
    "\n",
    "4. **Incremental Refinement:** Each block adds small improvements rather than completely transforming data\n",
    "\n",
    "### 🎨 Real-World Analogy\n",
    "\n",
    "**Photo Editing:**\n",
    "- ❌ Don't recreate the entire photo\n",
    "- ✓ Apply adjustments: brightness +10, contrast +5, sharpness +3\n",
    "\n",
    "Each adjustment is a \"residual\" that enhances the original. ResNet works the same way!\n",
    "\n",
    "**Video Game Save Points:**\n",
    "- ❌ Don't restart from beginning every level\n",
    "- ✓ Save progress at checkpoints, add new achievements\n",
    "\n",
    "Your final score = Original save + All improvements collected along the way! 🎮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Deep Dive: From Concept to Implementation\n",
    "\n",
    "Now let's see how the residual concept translates into actual network architecture:\n",
    "\n",
    "---\n",
    "\n",
    "### Image 1: Complete ResNet Architecture (Top View)\n",
    "<figure>\n",
    "  <img src=\"asset/ResNet.PNG\" alt=\"Full ResNet Architecture\" width=\"800\">\n",
    "</figure>\n",
    "\n",
    "**What This Shows:** The complete ResNet-50 architecture from input to output\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "**Horizontal Flow (Left to Right):**\n",
    "- **Input** (left): 224×224 RGB image\n",
    "- **Initial Conv + Pool**: Reduces to 56×56 (shown in boxes labeled \"conv1\", \"pool1\")\n",
    "- **Four Color-Coded Stages**: \n",
    "  - **Blue/Green blocks**: Layer 1 (56×56, 256 channels)\n",
    "  - **Orange blocks**: Layer 2 (28×28, 512 channels)\n",
    "  - **Pink blocks**: Layer 3 (14×14, 1024 channels)\n",
    "  - **Purple blocks**: Layer 4 (7×7, 2048 channels)\n",
    "- **Output** (right): Classification through pooling + FC layer\n",
    "\n",
    "**The U-Shaped Curves (Skip Connections):**\n",
    "- Each U-curve represents the **identity shortcut** we discussed!\n",
    "- They bypass the conv layers and add directly to the output\n",
    "- This is the physical manifestation of `Output = F(Input) + Input`\n",
    "\n",
    "**Why Multiple Rows?**\n",
    "- Top row: Shows the detailed 50-layer structure\n",
    "- Middle/Bottom rows: Different variants (ResNet-101, ResNet-152)\n",
    "- Notice how deeper variants have MORE blocks in the middle sections\n",
    "\n",
    "**Critical Understanding:** This diagram shows that ResNet isn't just \"a deep network\" - it's many small residual transformations chained together, with each block having its own skip connection.\n",
    "\n",
    "---\n",
    "\n",
    "### Image 2: Single Residual Block (Mathematical View)\n",
    "<figure>\n",
    "  <img src=\"asset/residual_block.png\" alt=\"Residual Block structure\" width=\"520\">\n",
    "</figure>\n",
    "\n",
    "**What This Shows:** The mathematical formula of ONE residual block\n",
    "\n",
    "**Reading the Diagram:**\n",
    "\n",
    "```\n",
    "Input: x\n",
    "    │\n",
    "    ├─────────────────────┐ (identity/skip path)\n",
    "    │                     │\n",
    "    ├─→ weight layer      │\n",
    "    ├─→ relu              │\n",
    "    ├─→ weight layer      │\n",
    "    │   (produces F(x))   │\n",
    "    │                     │\n",
    "    └────→ ⊕ ←───────────┘ (addition)\n",
    "           │\n",
    "        F(x) + x\n",
    "           │\n",
    "        → relu\n",
    "           │\n",
    "        Output\n",
    "```\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "1. **F(x)**: The residual function learned by weight layers\n",
    "   - In our code: conv1 → bn1 → relu → conv2 → bn2 → relu → conv3 → bn3\n",
    "   \n",
    "2. **x (identity)**: The skip connection\n",
    "   - In our code: `identity = x` (or downsampled if needed)\n",
    "   \n",
    "3. **⊕ (Addition)**: Element-wise addition\n",
    "   - In our code: `x += identity`\n",
    "   \n",
    "4. **Final ReLU**: Applied after addition\n",
    "   - In our code: `x = self.relu(x)`\n",
    "\n",
    "**Why This Formula Works:**\n",
    "- If identity mapping is optimal, F(x) can learn to be ≈ 0\n",
    "- If transformation is needed, F(x) learns the necessary changes\n",
    "- The skip connection ensures gradients always have a direct path backward\n",
    "\n",
    "---\n",
    "\n",
    "### Image 3: Two Implementation Styles (Post vs Pre-Activation)\n",
    "<figure>\n",
    "  <img src=\"asset/residual_block_two_methods.png\" alt=\"Technical Implementation of Residual Block with layers\" width=\"520\">\n",
    "</figure>\n",
    "\n",
    "**What This Shows:** Two ways to organize layers within a residual block\n",
    "\n",
    "#### Left Side: Post-Activation (Original ResNet)\n",
    "```\n",
    "x → Convolution → Batch Norm → ReLU → \n",
    "    Convolution → Batch Norm → [Add identity] → ReLU\n",
    "```\n",
    "\n",
    "**Flow:**\n",
    "- Input x splits into two paths\n",
    "- Main path: Conv → BN → ReLU → Conv → BN\n",
    "- Skip path: Direct (or downsample if needed)\n",
    "- **Addition happens BEFORE final ReLU**\n",
    "- Final ReLU applied to sum\n",
    "\n",
    "**Our Implementation Uses This!**\n",
    "```python\n",
    "x = self.conv3(x)\n",
    "x = self.bn3(x)        # No ReLU here!\n",
    "x += identity          # Addition\n",
    "x = self.relu(x)       # ReLU after addition\n",
    "```\n",
    "\n",
    "#### Right Side: Pre-Activation (ResNet v2)\n",
    "```\n",
    "x → Batch Norm → ReLU → Convolution → \n",
    "    Batch Norm → ReLU → Convolution → [Add identity]\n",
    "```\n",
    "\n",
    "**Flow:**\n",
    "- Activations applied BEFORE convolutions\n",
    "- No activation after final addition\n",
    "- Provides cleaner gradient flow\n",
    "\n",
    "**Comparison Table:**\n",
    "\n",
    "| Aspect | Post-Activation (Left) | Pre-Activation (Right) |\n",
    "|--------|----------------------|------------------------|\n",
    "| **Activation Placement** | After convolution | Before convolution |\n",
    "| **Addition Point** | Before final ReLU | After all operations |\n",
    "| **Used In** | ResNet-18/34/50/101/152 | ResNet-v2 (improved) |\n",
    "| **Gradient Flow** | Good | Better |\n",
    "| **Training Stability** | Stable | More stable for 1000+ layers |\n",
    "| **Our Implementation** | ✓ We use this | |\n",
    "\n",
    "**Why Post-Activation is Still Popular:**\n",
    "- Original design, well-understood\n",
    "- Excellent performance up to 152 layers\n",
    "- Simpler to understand and implement\n",
    "- Most pre-trained models use this version\n",
    "\n",
    "**When Pre-Activation Helps:**\n",
    "- Very deep networks (200+ layers)\n",
    "- Need maximum gradient flow\n",
    "- Research on extremely deep architectures\n",
    "\n",
    "---\n",
    "\n",
    "### Connecting the Diagrams to Our Code\n",
    "\n",
    "**From Architecture Diagram:**\n",
    "```python\n",
    "# This is ONE colored block in the top diagram\n",
    "residual_block(in_channels, out_channels, stride, downsample)\n",
    "```\n",
    "\n",
    "**From Mathematical Block:**\n",
    "```python\n",
    "identity = x                    # Skip path\n",
    "x = F(x)                       # Main path (weight layers)\n",
    "x = x + identity               # ⊕ Addition\n",
    "x = relu(x)                    # Final activation\n",
    "```\n",
    "\n",
    "**From Implementation Diagram:**\n",
    "```python\n",
    "# Post-activation style (what we implement)\n",
    "x = self.conv1(x)              # Blue: Convolution\n",
    "x = self.bn1(x)                # Green: Batch Norm\n",
    "x = self.relu(x)               # Pink: ReLU\n",
    "x = self.conv2(x)              # Blue: Convolution\n",
    "x = self.bn2(x)                # Green: Batch Norm\n",
    "x = self.relu(x)               # Pink: ReLU\n",
    "x = self.conv3(x)              # Blue: Convolution\n",
    "x = self.bn3(x)                # Green: Batch Norm\n",
    "x += identity                  # Orange ⊕: Addition\n",
    "x = self.relu(x)               # Pink: ReLU\n",
    "```\n",
    "\n",
    "The beauty is how these three perspectives (architecture, mathematics, implementation) all describe the same elegant solution to training very deep networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b87230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712d7c5",
   "metadata": {},
   "source": [
    "## Understanding ResNet Architecture: Building Blocks\n",
    "\n",
    "Before we dive into the code, let's understand what we're building:\n",
    "\n",
    "### What Problem Does ResNet Solve?\n",
    "\n",
    "When we stack many layers in a neural network, we face the **vanishing gradient problem**:\n",
    "- Gradients get smaller as they backpropagate through layers\n",
    "- Deep layers learn, but shallow layers barely update\n",
    "- Result: Adding more layers can actually **decrease** performance!\n",
    "\n",
    "### The ResNet Solution: Skip Connections\n",
    "\n",
    "ResNet introduces **residual connections** (skip connections):\n",
    "```\n",
    "Output = F(Input) + Input\n",
    "```\n",
    "\n",
    "Instead of learning the mapping `H(x)`, the network learns the residual `F(x) = H(x) - x`\n",
    "\n",
    "**Why is this easier?**\n",
    "- If the optimal mapping is close to identity (doing nothing), the network just needs to push `F(x)` toward zero\n",
    "- It's easier to learn small adjustments than to learn the entire transformation from scratch\n",
    "\n",
    "**Real-world analogy:** \n",
    "Think of photo editing. Instead of recreating the entire photo, you only adjust brightness, contrast, etc. That's exactly what residual learning does!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14113f36",
   "metadata": {},
   "source": [
    "## The Residual Block: The Heart of ResNet\n",
    "\n",
    "A residual block is the fundamental building unit of ResNet. Let's understand its components:\n",
    "\n",
    "### Architecture of a Bottleneck Residual Block\n",
    "\n",
    "The block we're implementing uses a **bottleneck design** with 3 convolutional layers:\n",
    "\n",
    "1. **1×1 Conv (Compression)**: Reduces channels → saves computation\n",
    "2. **3×3 Conv (Main Processing)**: Does the actual feature extraction\n",
    "3. **1×1 Conv (Expansion)**: Expands channels back (4x expansion factor)\n",
    "\n",
    "### Example Walkthrough\n",
    "\n",
    "Let's say input has shape `[batch_size, 256, 56, 56]` (256 channels, 56×56 spatial dimensions):\n",
    "\n",
    "**Main Path (learning the residual F(x)):**\n",
    "```\n",
    "Input: [B, 256, 56, 56]\n",
    "   ↓ 1×1 conv → 64 channels\n",
    "[B, 64, 56, 56]\n",
    "   ↓ 3×3 conv → 64 channels  \n",
    "[B, 64, 56, 56]\n",
    "   ↓ 1×1 conv → 64*4=256 channels\n",
    "[B, 256, 56, 56]\n",
    "```\n",
    "\n",
    "**Skip Path (identity shortcut):**\n",
    "```\n",
    "Input: [B, 256, 56, 56] → directly passes through → [B, 256, 56, 56]\n",
    "```\n",
    "\n",
    "**Final Addition:**\n",
    "```\n",
    "Output = Main_Path + Skip_Path = [B, 256, 56, 56]\n",
    "```\n",
    "\n",
    "### Why Bottleneck Design?\n",
    "\n",
    "**Without bottleneck** (two 3×3 convs with 256 channels):\n",
    "- Params: 256×256×3×3 + 256×256×3×3 = 1,179,648 parameters\n",
    "\n",
    "**With bottleneck** (1×1 → 3×3 → 1×1):\n",
    "- Params: 256×64×1×1 + 64×64×3×3 + 64×256×1×1 = 69,632 parameters\n",
    "\n",
    "That's **17× fewer parameters** for similar performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a9904",
   "metadata": {},
   "source": [
    "### Important: Class vs Instance Attributes\n",
    "\n",
    "Notice that `expansion = 4` is defined at the **class level**, not inside `__init__`:\n",
    "\n",
    "```python\n",
    "class residual_block(nn.Module):\n",
    "    expansion = 4  # ← Class attribute\n",
    "    \n",
    "    def __init__(self, ...):\n",
    "        # Instance attributes go here\n",
    "```\n",
    "\n",
    "**Why?**\n",
    "- The ResNet class needs to access `block.expansion` before creating any instances\n",
    "- In `_make_layer`, we use: `out_channels * block.expansion`\n",
    "- `block` here refers to the **class** itself, not an instance\n",
    "- Class attributes can be accessed via both the class (`residual_block.expansion`) and instances (`self.expansion`)\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "# Accessing as class attribute\n",
    "channels = 64 * residual_block.expansion  # Works! Returns 256\n",
    "\n",
    "# Accessing as instance attribute  \n",
    "block_instance = residual_block(256, 64)\n",
    "channels = 64 * block_instance.expansion  # Also works! Returns 256\n",
    "```\n",
    "\n",
    "If `expansion` were only in `__init__`, we'd get `AttributeError: type object 'residual_block' has no attribute 'expansion'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1bfb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual_block(nn.Module):\n",
    "    expansion = 4  # Class attribute - accessible as residual_block.expansion\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(residual_block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3=nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.identity_downsample=downsample\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "            \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2ec8e",
   "metadata": {},
   "source": [
    "## Code Implementation: Residual Block\n",
    "\n",
    "Now let's implement the bottleneck residual block step by step.\n",
    "\n",
    "### Key Parameters Explained:\n",
    "- **`in_channels`**: Number of input channels (e.g., 256)\n",
    "- **`out_channels`**: Base number of output channels (e.g., 64)\n",
    "- **`expansion=4`**: Final output will be `out_channels × 4` (e.g., 64×4=256)\n",
    "- **`stride`**: Controls spatial downsampling (stride=2 reduces H,W by half)\n",
    "- **`downsample`**: Optional layer to match dimensions for the skip connection\n",
    "\n",
    "### When Do We Need Downsampling?\n",
    "\n",
    "The skip connection requires: **Input dimensions = Output dimensions**\n",
    "\n",
    "Problem occurs when:\n",
    "1. **Spatial mismatch**: stride=2 makes output smaller (56×56 → 28×28)\n",
    "2. **Channel mismatch**: channels change (256 → 512)\n",
    "\n",
    "Solution: Use a 1×1 conv + BatchNorm to transform the identity/skip connection\n",
    "\n",
    "### Example Scenario:\n",
    "```\n",
    "Input:  [B, 256, 56, 56]\n",
    "stride = 2\n",
    "\n",
    "Main path output:     [B, 512, 28, 28]  (downsampled + more channels)\n",
    "Skip path (original): [B, 256, 56, 56]  ❌ Can't add these!\n",
    "\n",
    "Solution: Apply downsample to skip path\n",
    "Skip path (after):    [B, 512, 28, 28]  ✓ Now we can add!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0af322",
   "metadata": {},
   "source": [
    "### Understanding the Forward Pass\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "    identity = x  # Save for skip connection\n",
    "    \n",
    "    # Bottleneck path: learns F(x)\n",
    "    x = self.conv1(x)  # 1×1: reduce channels (256→64)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.conv2(x)  # 3×3: spatial processing\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.conv3(x)  # 1×1: expand channels (64→256)\n",
    "    x = self.bn3(x)\n",
    "    # No ReLU - need negative residuals too!\n",
    "    \n",
    "    # Match dimensions if needed\n",
    "    if self.identity_downsample is not None:\n",
    "        identity = self.identity_downsample(identity)\n",
    "    \n",
    "    x += identity      # THE KEY: Add skip connection\n",
    "    x = self.relu(x)   # Final activation\n",
    "    \n",
    "    return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Works: The 5 Critical Reasons\n",
    "\n",
    "**1. Gradient Flow**\n",
    "```\n",
    "Without skip: Gradient must flow through ALL conv layers (can vanish)\n",
    "With skip:    Gradient has direct path through addition (+1 term)\n",
    "```\n",
    "\n",
    "**2. Easier Learning Task**\n",
    "```\n",
    "Traditional: Learn complete transformation H(x)\n",
    "ResNet:      Learn residual F(x) = H(x) - x  (just the difference!)\n",
    "```\n",
    "Learning small adjustments is much easier than learning everything from scratch.\n",
    "\n",
    "**3. Identity Mapping**\n",
    "```python\n",
    "If no change needed: F(x) ≈ 0\n",
    "Result: Output ≈ Input  (identity preserved)\n",
    "```\n",
    "Network can choose to \"do nothing\" if that's optimal!\n",
    "\n",
    "**4. Flexible Depth**\n",
    "```\n",
    "Useful layers:   Learn meaningful F(x)\n",
    "Redundant layers: Learn F(x) ≈ 0, become near-identity\n",
    "```\n",
    "Network automatically uses effective depth, ignoring unnecessary layers.\n",
    "\n",
    "**5. Why No ReLU Before Addition**\n",
    "- ReLU forces values ≥ 0\n",
    "- Residuals need to be positive AND negative\n",
    "- Example: If optimal = input - 5, need to output -5 (ReLU would make it 0)\n",
    "\n",
    "---\n",
    "\n",
    "### Dimension Matching: When Downsample is Needed\n",
    "\n",
    "```python\n",
    "if stride != 1 or self.in_channels != out_channels * 4:\n",
    "    downsample = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels*4, kernel_size=1, stride=stride),\n",
    "        nn.BatchNorm2d(out_channels*4)\n",
    "    )\n",
    "```\n",
    "\n",
    "**Why needed?** For addition `x + identity`, both must have same shape!\n",
    "\n",
    "**Two scenarios requiring transformation:**\n",
    "\n",
    "| Condition | Problem | Solution |\n",
    "|-----------|---------|----------|\n",
    "| `stride != 1` | Spatial mismatch: [B,C,56,56] + [B,C,28,28] ❌ | Apply stride to identity |\n",
    "| Channels changed | Channel mismatch: [B,256,H,W] + [B,512,H,W] ❌ | 1×1 conv to match channels |\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Main path:  [B, 256, 56, 56] → stride=2 → [B, 512, 28, 28]\n",
    "Identity:   [B, 256, 56, 56] → downsample → [B, 512, 28, 28] ✓\n",
    "Now can add: 512 + 512 = 512 channels, both 28×28\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1dfe9c",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"asset/resnet_blocks_add.png\" alt=\"Resnet architecture blocks step by step\" width=\"800\">\n",
    "</figure>\n",
    "\n",
    "The diagram shows the **ResNet-50 architecture**, which consists of 50 layers built using *residual blocks*. The input first goes through a 7×7 convolution (stride 2) and max pooling to extract basic features. Then, several stages of residual blocks follow — each containing 1×1, 3×3, and 1×1 convolutions with increasing filter sizes (64→256, 128→512, 256→1024, 512→2048). These blocks help the network learn deep features efficiently using skip connections that prevent vanishing gradients. Afterward, an average pooling layer condenses the spatial data, and a fully connected layer with a softmax output predicts the final class. Altogether, these components sum to **50 layers**, forming the **ResNet-50** model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c02134",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"asset/ResNet_chart.png\" alt=\"Full ResNet Architecture\" width=\"800\">\n",
    "</figure>\n",
    "This table compares the ResNet family architectures — specifically ResNet-18, 34, 50, 101, and 152 layers — showing how each model is structured by layer blocks and filter sizes.\n",
    "\n",
    "| Block   | Output Size | Function            | Example (ResNet-50)               |\n",
    "| ------- | ----------- | ------------------- | --------------------------------- |\n",
    "| conv2_x | 56×56       | Shallow features    | [1×1,64 → 3×3,64 → 1×1,256] ×3    |\n",
    "| conv3_x | 28×28       | Mid-level features  | [1×1,128 → 3×3,128 → 1×1,512] ×4  |\n",
    "| conv4_x | 14×14       | Deep features       | [1×1,256 → 3×3,256 → 1×1,1024] ×6 |\n",
    "| conv5_x | 7×7         | High-level features | [1×1,512 → 3×3,512 → 1×1,2048] ×3 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d70e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, res_block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(res_block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(res_block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(res_block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(res_block, layers[3], out_channels=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * res_block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, blocks, out_channels, stride):\n",
    "        downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        \n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial convolution and pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Four residual layer groups\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Classification head\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2403a",
   "metadata": {},
   "source": [
    "## The Forward Pass: Complete Data Flow\n",
    "\n",
    "The `forward` method defines how data flows through the entire ResNet:\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "### Step-by-Step Data Transformation\n",
    "\n",
    "**Phase 1: Initial Feature Extraction**\n",
    "```python\n",
    "x = self.conv1(x)      # [B, 3, 224, 224] → [B, 64, 112, 112]\n",
    "x = self.bn1(x)        # Normalize\n",
    "x = self.relu(x)       # Activate\n",
    "x = self.maxpool(x)    # [B, 64, 112, 112] → [B, 64, 56, 56]\n",
    "```\n",
    "First, extract basic features and reduce spatial dimensions.\n",
    "\n",
    "**Phase 2: Residual Learning (The Core!)**\n",
    "```python\n",
    "x = self.layer1(x)     # [B, 64, 56, 56] → [B, 256, 56, 56]\n",
    "x = self.layer2(x)     # [B, 256, 56, 56] → [B, 512, 28, 28]\n",
    "x = self.layer3(x)     # [B, 512, 28, 28] → [B, 1024, 14, 14]\n",
    "x = self.layer4(x)     # [B, 1024, 14, 14] → [B, 2048, 7, 7]\n",
    "```\n",
    "Each layer group applies multiple residual blocks:\n",
    "- Early layers learn edges and textures\n",
    "- Middle layers learn object parts\n",
    "- Deep layers learn high-level concepts\n",
    "\n",
    "**Phase 3: Classification**\n",
    "```python\n",
    "x = self.avgpool(x)       # [B, 2048, 7, 7] → [B, 2048, 1, 1]\n",
    "x = torch.flatten(x, 1)   # [B, 2048, 1, 1] → [B, 2048]\n",
    "x = self.fc(x)            # [B, 2048] → [B, 1000]\n",
    "```\n",
    "- **AdaptiveAvgPool**: Averages each channel's spatial dimensions to single value\n",
    "- **Flatten**: Converts to 1D vector (keeps batch dimension)\n",
    "- **FC layer**: Maps features to class predictions\n",
    "\n",
    "### Why This Flow Works\n",
    "\n",
    "The forward pass creates a **hierarchical feature extractor**:\n",
    "- Information flows through many layers (50-152!)\n",
    "- Skip connections in each block prevent information loss\n",
    "- Progressively reduces spatial size while increasing channel depth\n",
    "- Final pooling makes the network resolution-invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456c716",
   "metadata": {},
   "source": [
    "## Building the Complete ResNet: Stacking Residual Blocks\n",
    "\n",
    "Now we build the full ResNet by stacking multiple residual blocks together. This is where the architecture becomes truly powerful!\n",
    "\n",
    "### ResNet Architecture Overview\n",
    "\n",
    "A complete ResNet has this structure:\n",
    "\n",
    "1. **Initial Conv Layer**: 7×7 conv + BatchNorm + ReLU + MaxPool\n",
    "   - Reduces spatial dimensions and extracts initial features\n",
    "   \n",
    "2. **Four Layer Groups**: Each group contains multiple residual blocks\n",
    "   - Layer 1: 64 channels, no spatial reduction\n",
    "   - Layer 2: 128 channels, spatial reduction (stride=2)\n",
    "   - Layer 3: 256 channels, spatial reduction (stride=2)\n",
    "   - Layer 4: 512 channels, spatial reduction (stride=2)\n",
    "   \n",
    "3. **Classification Head**: Global Average Pooling + Fully Connected\n",
    "   - Converts feature maps to class predictions\n",
    "\n",
    "### How Residual Blocks Work Together in ResNet\n",
    "\n",
    "Each layer group contains multiple residual blocks connected in sequence:\n",
    "\n",
    "```\n",
    "Input Image [224×224×3]\n",
    "    ↓\n",
    "Conv1 + BN + ReLU + MaxPool → [56×56×64]\n",
    "    ↓\n",
    "┌─────────────────────────────────┐\n",
    "│ Layer 1: 3 residual blocks      │  [56×56×256]\n",
    "│ Block 1: 64 → 256 channels      │  ← First block may need downsample\n",
    "│ Block 2: 256 → 256 (identity)   │  ← Later blocks use identity\n",
    "│ Block 3: 256 → 256 (identity)   │\n",
    "└─────────────────────────────────┘\n",
    "    ↓\n",
    "┌─────────────────────────────────┐\n",
    "│ Layer 2: 4 residual blocks      │  [28×28×512]\n",
    "│ Block 1: 256 → 512 (stride=2)   │  ← First block downsamples + increases channels\n",
    "│ Block 2-4: 512 → 512 (identity) │  ← Others maintain dimensions\n",
    "└─────────────────────────────────┘\n",
    "    ↓\n",
    "... (Layer 3 and Layer 4 follow same pattern)\n",
    "    ↓\n",
    "Global Average Pool + FC → [1000 classes]\n",
    "```\n",
    "\n",
    "### The Pattern: First Block Special, Others Simple\n",
    "\n",
    "**First block in each layer:**\n",
    "- Changes number of channels (64→256, 256→512, etc.)\n",
    "- May reduce spatial dimensions (stride=2)\n",
    "- Needs downsample for skip connection\n",
    "\n",
    "**Remaining blocks in the layer:**\n",
    "- Keep same dimensions throughout\n",
    "- Pure residual learning (no dimension changes)\n",
    "- Skip connection is direct (identity mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abf283",
   "metadata": {},
   "source": [
    "## Code Implementation: ResNet Class\n",
    "\n",
    "### Constructor Parameters\n",
    "\n",
    "- **`res_block`**: The residual block class (we pass `residual_block`)\n",
    "- **`layers`**: List of 4 numbers specifying blocks per layer\n",
    "  - Example: `[3, 4, 6, 3]` for ResNet-50\n",
    "  - Means: 3 blocks in layer1, 4 in layer2, 6 in layer3, 3 in layer4\n",
    "- **`image_channels`**: Input channels (3 for RGB images)\n",
    "- **`num_classes`**: Number of output classes (1000 for ImageNet)\n",
    "\n",
    "### Understanding `self.in_channels`\n",
    "\n",
    "This is a **tracking variable** that changes as we go deeper:\n",
    "\n",
    "```\n",
    "Initial:        self.in_channels = 64  (after first conv)\n",
    "After layer1:   self.in_channels = 64 * 4 = 256\n",
    "After layer2:   self.in_channels = 128 * 4 = 512\n",
    "After layer3:   self.in_channels = 256 * 4 = 1024\n",
    "After layer4:   self.in_channels = 512 * 4 = 2048\n",
    "```\n",
    "\n",
    "It tracks what channels are coming into the next layer!\n",
    "\n",
    "### Initial Layers Explained\n",
    "\n",
    "```python\n",
    "self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "```\n",
    "- Large 7×7 kernel to capture initial patterns\n",
    "- Stride=2 reduces size: 224×224 → 112×112\n",
    "- Output: 64 feature maps\n",
    "\n",
    "```python\n",
    "self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "```\n",
    "- Further reduces size: 112×112 → 56×56\n",
    "- Helps make network more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808408c",
   "metadata": {},
   "source": [
    "## The `_make_layer` Method: Building Block Groups\n",
    "\n",
    "```python\n",
    "def _make_layer(self, block, blocks, out_channels, stride):\n",
    "    \"\"\"\n",
    "    Creates a layer with multiple residual blocks\n",
    "    \n",
    "    Args:\n",
    "        block: residual_block class\n",
    "        blocks: number of blocks to stack (e.g., 3 for layer1)\n",
    "        out_channels: base channel count\n",
    "        stride: spatial downsampling (only first block)\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Purpose**: Automate creation of layer groups (layer1-4), each with multiple blocks\n",
    "\n",
    "---\n",
    "\n",
    "### The Pattern: First Block vs Remaining Blocks\n",
    "\n",
    "**First block**: Handles dimension changes (stride + channels)  \n",
    "**Remaining blocks**: Pure residual learning at fixed dimensions\n",
    "\n",
    "```python\n",
    "# Example: Creating layer2 with 4 blocks\n",
    "layer2 = _make_layer(block=residual_block, blocks=4, out_channels=128, stride=2)\n",
    "\n",
    "Block 1: [256, 56×56] → [512, 28×28]  ← Transition (stride=2, downsample)\n",
    "Block 2: [512, 28×28] → [512, 28×28]  ← Refinement (stride=1)\n",
    "Block 3: [512, 28×28] → [512, 28×28]  ← Refinement (stride=1)\n",
    "Block 4: [512, 28×28] → [512, 28×28]  ← Refinement (stride=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-Step Construction\n",
    "\n",
    "#### **Step 1: Check if Downsample Needed**\n",
    "```python\n",
    "downsample = None\n",
    "if stride != 1 or self.in_channels != out_channels * 4:\n",
    "    downsample = nn.Sequential(\n",
    "        nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride),\n",
    "        nn.BatchNorm2d(out_channels*4)\n",
    "    )\n",
    "```\n",
    "\n",
    "**When is it needed?**\n",
    "- `stride != 1`: Spatial dimensions change\n",
    "- `in_channels != out_channels*4`: Channel count changes\n",
    "\n",
    "**Why 1×1 conv?** Minimal parameters, preserves information, matches dimensions efficiently\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Create First Block**\n",
    "```python\n",
    "layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "self.in_channels = out_channels * 4  # Update for next layer\n",
    "```\n",
    "\n",
    "**Responsibilities**:\n",
    "1. Accept input from previous layer\n",
    "2. Apply spatial downsampling (if stride > 1)\n",
    "3. Expand channels (via expansion=4)\n",
    "4. Transform identity to match\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Create Remaining Blocks**\n",
    "```python\n",
    "for _ in range(1, blocks):  # Start from 1!\n",
    "    layers.append(block(self.in_channels, out_channels))\n",
    "```\n",
    "\n",
    "**Why simpler?**\n",
    "- No stride (dimensions already set by first block)\n",
    "- No downsample (identity already matches)\n",
    "- Just pure residual learning: `Output = F(x) + x`\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Combine into Sequential**\n",
    "```python\n",
    "return nn.Sequential(*layers)\n",
    "```\n",
    "\n",
    "Unpacks list into Sequential container for easy forward pass.\n",
    "\n",
    "---\n",
    "\n",
    "### Complete Example: Building ResNet-50\n",
    "\n",
    "```python\n",
    "# ResNet-50 configuration: [3, 4, 6, 3] blocks\n",
    "self.layer1 = self._make_layer(residual_block, 3, 64, stride=1)\n",
    "# → 3 blocks, 256 channels, 56×56 (no spatial reduction)\n",
    "\n",
    "self.layer2 = self._make_layer(residual_block, 4, 128, stride=2)\n",
    "# → 4 blocks, 512 channels, 28×28 (reduce spatial by 2)\n",
    "\n",
    "self.layer3 = self._make_layer(residual_block, 6, 256, stride=2)\n",
    "# → 6 blocks, 1024 channels, 14×14 (reduce spatial by 2)\n",
    "\n",
    "self.layer4 = self._make_layer(residual_block, 3, 512, stride=2)\n",
    "# → 3 blocks, 2048 channels, 7×7 (reduce spatial by 2)\n",
    "```\n",
    "\n",
    "**Total**: 3+4+6+3 = 16 residual blocks = 48 conv layers + initial conv + FC = 50 layers!\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Design is Brilliant\n",
    "\n",
    "**Modularity**: One method creates all 4 layer groups  \n",
    "**Flexibility**: Easy to create ResNet-101 (change to [3,4,23,3]) or ResNet-152 ([3,8,36,3])  \n",
    "**Dimension Management**: Automatically handles all size transitions  \n",
    "**Residual Learning**: First block transitions, rest refine features\n",
    "\n",
    "The `_make_layer` method is the key to building arbitrarily deep ResNets! 🔧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f83ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(image_channels=3, num_classes=1000):\n",
    "    return ResNet(residual_block, [3, 4, 6, 3], image_channels, num_classes)\n",
    "\n",
    "def ResNet101(image_channels=3, num_classes=1000):\n",
    "    return ResNet(residual_block, [3, 4, 23, 3], image_channels, num_classes)\n",
    "\n",
    "def ResNet152(image_channels=3, num_classes=1000):\n",
    "    return ResNet(residual_block, [3, 8, 36, 3], image_channels, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91fb44",
   "metadata": {},
   "source": [
    "## Creating Different ResNet Variants\n",
    "\n",
    "ResNet comes in different depths. The only difference is the number of blocks in each layer!\n",
    "\n",
    "### The Architecture Formula\n",
    "\n",
    "All variants follow: `[Layer1, Layer2, Layer3, Layer4]` pattern\n",
    "\n",
    "| Model | Blocks per Layer | Total Layers | Parameters |\n",
    "|-------|-----------------|--------------|------------|\n",
    "| **ResNet-50** | [3, 4, 6, 3] | 50 | ~25.6M |\n",
    "| **ResNet-101** | [3, 4, 23, 3] | 101 | ~44.5M |\n",
    "| **ResNet-152** | [3, 8, 36, 3] | 152 | ~60.2M |\n",
    "\n",
    "### How to Count Layers\n",
    "\n",
    "Each residual block has 3 conv layers (1×1, 3×3, 1×1).\n",
    "\n",
    "**For ResNet-50:**\n",
    "```\n",
    "Initial conv:        1 layer\n",
    "Layer 1: 3 blocks × 3 convs = 9 layers\n",
    "Layer 2: 4 blocks × 3 convs = 12 layers\n",
    "Layer 3: 6 blocks × 3 convs = 18 layers\n",
    "Layer 4: 3 blocks × 3 convs = 9 layers\n",
    "Final FC:            1 layer\n",
    "─────────────────────────────────\n",
    "Total:               1 + 48 + 1 = 50 layers ✓\n",
    "```\n",
    "\n",
    "### Detailed Architecture of ResNet-50\n",
    "\n",
    "Let's trace input through ResNet-50 with input `[B, 3, 224, 224]`:\n",
    "\n",
    "```\n",
    "Input: [B, 3, 224, 224]\n",
    "    ↓ Conv1 (7×7, stride=2) + BN + ReLU\n",
    "[B, 64, 112, 112]\n",
    "    ↓ MaxPool (3×3, stride=2)\n",
    "[B, 64, 56, 56]\n",
    "    ↓ Layer 1: [3, 4, 6, 3][0] = 3 blocks, out_channels=64, stride=1\n",
    "    │ Block 1: 64 → 64 → 64 → 256 (expansion!)\n",
    "    │ Block 2: 256 → 64 → 64 → 256 (identity)\n",
    "    │ Block 3: 256 → 64 → 64 → 256 (identity)\n",
    "[B, 256, 56, 56]\n",
    "    ↓ Layer 2: [3, 4, 6, 3][1] = 4 blocks, out_channels=128, stride=2\n",
    "    │ Block 1: 256 → 128 → 128 → 512 (downsample + expand!)\n",
    "    │ Blocks 2-4: 512 → 128 → 128 → 512 (identity × 3)\n",
    "[B, 512, 28, 28]\n",
    "    ↓ Layer 3: [3, 4, 6, 3][2] = 6 blocks, out_channels=256, stride=2\n",
    "    │ Block 1: 512 → 256 → 256 → 1024 (downsample + expand!)\n",
    "    │ Blocks 2-6: 1024 → 256 → 256 → 1024 (identity × 5)\n",
    "[B, 1024, 14, 14]\n",
    "    ↓ Layer 4: [3, 4, 6, 3][3] = 3 blocks, out_channels=512, stride=2\n",
    "    │ Block 1: 1024 → 512 → 512 → 2048 (downsample + expand!)\n",
    "    │ Blocks 2-3: 2048 → 512 → 512 → 2048 (identity × 2)\n",
    "[B, 2048, 7, 7]\n",
    "    ↓ AdaptiveAvgPool → (1, 1)\n",
    "[B, 2048, 1, 1]\n",
    "    ↓ Flatten + FC(2048 → 1000)\n",
    "[B, 1000]  ← Class predictions!\n",
    "```\n",
    "\n",
    "### Why Different Variants?\n",
    "\n",
    "- **ResNet-50**: Good balance of accuracy and speed (most commonly used)\n",
    "- **ResNet-101**: Higher accuracy, more computation (better for complex tasks)\n",
    "- **ResNet-152**: Best accuracy, slowest (research/competitions)\n",
    "\n",
    "The deeper the network, the more residual blocks we stack, allowing it to learn more complex hierarchical features. The skip connections ensure that even with 152 layers, gradients still flow effectively!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ce9fc",
   "metadata": {},
   "source": [
    "## Testing Our ResNet Implementation\n",
    "\n",
    "Let's verify our implementation works correctly by creating a model and passing dummy input through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b86e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 224, 224])\n",
      "Output shape: torch.Size([2, 1000])\n",
      "\n",
      "Model successfully processes input!\n",
      "Each image gets 1000 class scores (logits)\n"
     ]
    }
   ],
   "source": [
    "# Create a ResNet-50 model\n",
    "model = ResNet50(image_channels=3, num_classes=1000)\n",
    "\n",
    "# Create dummy input (batch of 2 RGB images, 224×224)\n",
    "dummy_input = torch.randn(2, 3, 224, 224)\n",
    "\n",
    "# Forward pass\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nModel successfully processes input!\")\n",
    "print(f\"Each image gets {output.shape[1]} class scores (logits)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb404d72",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "The output shape `[2, 1000]` means:\n",
    "- **2**: Batch size (we passed 2 images)\n",
    "- **1000**: Logits for 1000 ImageNet classes\n",
    "\n",
    "These are raw scores (logits). To get probabilities, apply softmax:\n",
    "```python\n",
    "probabilities = torch.softmax(output, dim=1)\n",
    "predicted_classes = torch.argmax(output, dim=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd3fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in ResNet-50: 25,557,032\n",
      "That's approximately 25.6 million parameters!\n",
      "\n",
      "Model Architecture Overview:\n",
      "- Input: RGB images (3 channels)\n",
      "- Layer 1: 3 blocks → 256 channels\n",
      "- Layer 2: 4 blocks → 512 channels\n",
      "- Layer 3: 6 blocks → 1024 channels\n",
      "- Layer 4: 3 blocks → 2048 channels\n",
      "- Output: 1000 classes\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of parameters in our model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters in ResNet-50: {num_params:,}\")\n",
    "print(f\"That's approximately {num_params/1e6:.1f} million parameters!\")\n",
    "\n",
    "# Show model architecture summary\n",
    "print(f\"\\nModel Architecture Overview:\")\n",
    "print(f\"- Input: RGB images (3 channels)\")\n",
    "print(f\"- Layer 1: {len(model.layer1)} blocks → 256 channels\")\n",
    "print(f\"- Layer 2: {len(model.layer2)} blocks → 512 channels\") \n",
    "print(f\"- Layer 3: {len(model.layer3)} blocks → 1024 channels\")\n",
    "print(f\"- Layer 4: {len(model.layer4)} blocks → 2048 channels\")\n",
    "print(f\"- Output: {model.fc.out_features} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ecaac",
   "metadata": {},
   "source": [
    "## Key Takeaways: How Residual Blocks and ResNet Work Together\n",
    "\n",
    "### The Synergy Between Components\n",
    "\n",
    "**1. Individual Residual Block's Role:**\n",
    "- Learns **refinements/adjustments** rather than complete transformations\n",
    "- Uses skip connection: `Output = F(Input) + Input`\n",
    "- If a block isn't useful, it can learn F(x) ≈ 0, letting information pass through unchanged\n",
    "- Bottleneck design (1×1 → 3×3 → 1×1) reduces parameters while maintaining expressiveness\n",
    "\n",
    "**2. How Blocks Stack in ResNet:**\n",
    "- **First block in each layer**: Handles dimension changes (channels and spatial)\n",
    "- **Subsequent blocks**: Pure residual learning at constant dimensions\n",
    "- **Four layer groups**: Progressively increase channels while decreasing spatial dimensions\n",
    "- **Result**: A deep hierarchy of feature detectors (50-152 layers!)\n",
    "\n",
    "**3. The Power of Their Combination:**\n",
    "\n",
    "```\n",
    "Early layers (Layer 1-2): Learn low-level features\n",
    "   ↓ (edges, textures, simple patterns)\n",
    "   ↓ Skip connections ensure these features flow forward\n",
    "   ↓\n",
    "Middle layers (Layer 3): Learn mid-level features  \n",
    "   ↓ (parts of objects, combinations of simple patterns)\n",
    "   ↓ Each block refines without losing earlier information\n",
    "   ↓\n",
    "Deep layers (Layer 4): Learn high-level semantic features\n",
    "   ↓ (whole objects, complex patterns, context)\n",
    "   ↓ Even at this depth, gradients flow back effectively\n",
    "   ↓\n",
    "Classification: All levels of features available for decision\n",
    "```\n",
    "\n",
    "### Why This Architecture Revolutionized Deep Learning\n",
    "\n",
    "1. **Solves Degradation Problem**: Very deep networks train successfully\n",
    "2. **Efficient Gradient Flow**: Skip connections create \"highway\" for gradients\n",
    "3. **Flexible Learning**: Network can choose to use or skip layers as needed\n",
    "4. **Scalable**: Same architecture scales from 50 to 152+ layers\n",
    "5. **Reusable**: Pre-trained ResNets transfer well to other tasks\n",
    "\n",
    "### Practical Impact\n",
    "\n",
    "- **ImageNet**: 3.57% top-5 error (ResNet-152)\n",
    "- **COCO**: State-of-the-art object detection and segmentation\n",
    "- **Transfer Learning**: Most popular backbone for computer vision tasks\n",
    "- **Medical Imaging**: Enables deep networks for diagnosis tasks\n",
    "\n",
    "The elegance of ResNet is in its simplicity: just add the input to the output. This one simple idea enables training networks with 100+ layers effectively!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda920d0",
   "metadata": {},
   "source": [
    "## Quick Reference: ResNet Architecture Summary\n",
    "\n",
    "### Building Blocks Hierarchy\n",
    "\n",
    "```\n",
    "ResNet (Full Network)\n",
    "    │\n",
    "    ├─ Initial Processing\n",
    "    │   └─ Conv7×7 → BN → ReLU → MaxPool\n",
    "    │\n",
    "    ├─ Layer 1 (multiple Residual Blocks)\n",
    "    │   ├─ Block 1 (may need downsample)\n",
    "    │   ├─ Block 2 (identity)\n",
    "    │   └─ Block n (identity)\n",
    "    │\n",
    "    ├─ Layer 2 (multiple Residual Blocks)\n",
    "    │   ├─ Block 1 (downsample spatially)\n",
    "    │   └─ Block 2-n (identity)\n",
    "    │\n",
    "    ├─ Layer 3 (multiple Residual Blocks)\n",
    "    │   ├─ Block 1 (downsample spatially)\n",
    "    │   └─ Block 2-n (identity)\n",
    "    │\n",
    "    ├─ Layer 4 (multiple Residual Blocks)\n",
    "    │   ├─ Block 1 (downsample spatially)\n",
    "    │   └─ Block 2-n (identity)\n",
    "    │\n",
    "    └─ Classification Head\n",
    "        └─ GlobalAvgPool → FC\n",
    "```\n",
    "\n",
    "### Each Residual Block Contains\n",
    "\n",
    "```\n",
    "Input\n",
    "  │\n",
    "  ├─────────────────────┐ (Skip Connection)\n",
    "  │                     │\n",
    "  ├─ Conv 1×1 (reduce)  │\n",
    "  ├─ BN + ReLU          │\n",
    "  ├─ Conv 3×3 (process) │\n",
    "  ├─ BN + ReLU          │\n",
    "  ├─ Conv 1×1 (expand)  │\n",
    "  ├─ BN                 │\n",
    "  │                     │\n",
    "  └──────── + ──────────┘ (Addition)\n",
    "           │\n",
    "        ReLU\n",
    "           │\n",
    "        Output\n",
    "```\n",
    "\n",
    "### Channel Progression in ResNet-50\n",
    "\n",
    "| Stage | Output Size | Channels | Blocks | Stride |\n",
    "|-------|------------|----------|--------|--------|\n",
    "| Input | 224×224 | 3 | - | - |\n",
    "| Conv1 | 112×112 | 64 | 1 | 2 |\n",
    "| MaxPool | 56×56 | 64 | - | 2 |\n",
    "| Layer1 | 56×56 | 256 | 3 | 1 |\n",
    "| Layer2 | 28×28 | 512 | 4 | 2 |\n",
    "| Layer3 | 14×14 | 1024 | 6 | 2 |\n",
    "| Layer4 | 7×7 | 2048 | 3 | 2 |\n",
    "| AvgPool | 1×1 | 2048 | - | - |\n",
    "| FC | - | 1000 | - | - |\n",
    "\n",
    "Notice the pattern:\n",
    "- **Spatial dimensions**: Decrease by half each layer (56→28→14→7)\n",
    "- **Channels**: Double each layer (256→512→1024→2048)\n",
    "- **More blocks in middle layers**: Layer 3 has most blocks (6 for ResNet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b59a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
