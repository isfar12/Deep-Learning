{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a7c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb997f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9b4e8",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"asset/inception_module.png\" alt=\"InceptioModule\" width=\"600\">\n",
    "</figure>\n",
    "\n",
    "\n",
    "---\n",
    "This diagram is the **Inception module** (from Google’s *GoogLeNet/Inception v1* architecture), and it shows how the model combines multiple convolutional operations of different sizes *in parallel*.\n",
    "\n",
    "### 1. The problem before Inception\n",
    "\n",
    "If you just stacked (3 X 3) and (5 X 5) convolutions directly on top of a previous layer, the number of parameters would explode. Each large kernel (especially (5 X 5)) multiplies the number of input channels by the number of filters — computationally heavy and memory-hungry.\n",
    "\n",
    "So, the Inception idea was: *What if we shrink the depth (number of channels) before applying big kernels?*\n",
    "\n",
    "That’s where **dimensionality reduction** with (1 X 1) convolutions comes in.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Step-by-step flow\n",
    "\n",
    "#### **From the “Previous Layer”**\n",
    "\n",
    "You start with a feature map — think of it as a cube of data with many channels.\n",
    "\n",
    "From here, the data flows into **four parallel paths**:\n",
    "\n",
    "\n",
    "#### **Path 1: Simple 1×1 Convolution**\n",
    "\n",
    "This path directly applies a (1 X 1) convolution.\n",
    "It captures fine-grained local interactions between channels and provides a lightweight transformation — useful for introducing non-linearity (after ReLU) without increasing parameters.\n",
    "\n",
    "\n",
    "\n",
    "#### **Path 2: 1×1 → 3×3 Convolution (Reduction before Expansion)**\n",
    "\n",
    "* First, a **(1 X 1)** convolution reduces the depth — fewer channels.\n",
    "* Then, a **(3 X 3)** convolution processes the spatial information, but now it’s operating on a smaller number of input channels.\n",
    "\n",
    "This reduction step drastically cuts down computation while keeping the receptive field of (3 X 3).\n",
    "\n",
    "\n",
    "\n",
    "#### **Path 3: 1×1 → 5×5 Convolution (Heavier kernel, but reduced input)**\n",
    "\n",
    "* The **(1 X 1)** convolution again reduces the depth.\n",
    "* The **(5 X 5)** convolution then captures larger spatial patterns (wider context), but thanks to the reduction, it’s not computationally prohibitive.\n",
    "\n",
    "This is the main *dimensionality reduction* path — otherwise, (5 X 5) filters would be very expensive.\n",
    "\n",
    "\n",
    "#### **Path 4: 3×3 Max Pooling → 1×1 Convolution**\n",
    "\n",
    "Pooling operations don’t change the number of channels — so right after pooling, a **(1 X 1)** convolution is used to *project* (reduce or transform) the pooled output to a smaller or more balanced depth, ensuring that all branches can be concatenated later.\n",
    "\n",
    "\n",
    "---\n",
    "### 3. Final Step: **Filter Concatenation**\n",
    "\n",
    "After all these paths process the same input in different ways:\n",
    "\n",
    "* The feature maps from all paths are **concatenated along the channel dimension**.\n",
    "  This gives the network multiple levels of abstraction (fine to coarse features) in one unified output tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb83549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_pool):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        # 1x1 convolution branch\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_1x1, kernel_size=1), # reduce channels\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # 1x1 convolution followed by 3x3 convolution branch\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, red_3x3, kernel_size=1), # reduce channels\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(red_3x3, out_3x3, kernel_size=3, padding=1), # 3x3 conv\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # 1x1 convolution followed by 5x5 convolution branch\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, red_5x5, kernel_size=1), # reduce channels\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(red_5x5, out_5x5, kernel_size=5, padding=2), # 5x5 conv\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # 3x3 max pooling followed by 1x1 convolution branch\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),   # 3x3 max pooling\n",
    "            nn.Conv2d(in_channels, out_pool, kernel_size=1), # 1x1 conv\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1_out = self.branch1(x)\n",
    "        branch2_out = self.branch2(x)\n",
    "        branch3_out = self.branch3(x)\n",
    "        branch4_out = self.branch4(x)\n",
    "\n",
    "        # Concatenate outputs along the channel dimension\n",
    "        outputs = [branch1_out, branch2_out, branch3_out, branch4_out]\n",
    "        return torch.cat(outputs, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4b9e7",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"asset/google_net_arch.png\" alt=\"GoogleNet\" width=\"700\" height =\"500\">\n",
    "  <figcaption>GoogleNet arch From Original Paper\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc792521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(GoogleNet,self).__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv2= conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # format :  in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_pool\n",
    "        self.inception3a= InceptionModule(in_channels=192, out_1x1=64, red_3x3=96, out_3x3=128, red_5x5=16, out_5x5=32, out_pool=32)\n",
    "        self.inception3b= InceptionModule(in_channels=256, out_1x1=128, red_3x3=128, out_3x3=192, red_5x5=32, out_5x5=96, out_pool=64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception4a= InceptionModule(in_channels=480, out_1x1=192, red_3x3=96, out_3x3=208, red_5x5=16, out_5x5=48, out_pool=64)\n",
    "        self.inception4b= InceptionModule(in_channels=512, out_1x1=160, red_3x3=112, out_3x3=224, red_5x5=24, out_5x5=64, out_pool=64)\n",
    "        self.inception4c= InceptionModule(in_channels=512, out_1x1=128, red_3x3=128, out_3x3=256, red_5x5=24, out_5x5=64, out_pool=64)\n",
    "        self.inception4d= InceptionModule(in_channels=512, out_1x1=112, red_3x3=144, out_3x3=288, red_5x5=32, out_5x5=64, out_pool=64)\n",
    "        self.inception4e= InceptionModule(in_channels=528, out_1x1=256, red_3x3=160, out_3x3=320, red_5x5=32, out_5x5=128, out_pool=128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception5a= InceptionModule(in_channels=832, out_1x1=256, red_3x3=160, out_3x3=320, red_5x5=32, out_5x5=128, out_pool=128)\n",
    "        self.inception5b= InceptionModule(in_channels=832, out_1x1=384, red_3x3=192, out_3x3=384, red_5x5=48, out_5x5=128, out_pool=128)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984cc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
